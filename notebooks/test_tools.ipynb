{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5ebb46-479f-45b8-b614-cf9b6dfcada3",
   "metadata": {},
   "source": [
    "# web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5033fa05-4771-4964-93eb-f1a9f0b54c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.tools import FunctionTool\n",
    "from ddgs import DDGS\n",
    "import requests\n",
    "from markdownify import markdownify as html_to_md\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return text\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\" {2,}\", \" \", text)\n",
    "    text = \"\\n\".join(line.strip() for line in text.splitlines())\n",
    "    return text.strip()\n",
    "\n",
    "class DuckDuckGoAPI:\n",
    "    \"\"\"Backend wrapper around DuckDuckGo search + page fetching.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ddg = DDGS()\n",
    "\n",
    "    def search(self, query: str, page: int = 1, max_results: int = 10):\n",
    "        \"\"\"\n",
    "        DuckDuckGo search\n",
    "        \"\"\"\n",
    "\n",
    "        # DuckDuckGo Search API (text search)\n",
    "        results = list(\n",
    "            self.ddg.text(\n",
    "                query=query,\n",
    "                region=\"wt-wt\",\n",
    "                safesearch=\"moderate\",\n",
    "                timelimit=\"y\",\n",
    "                max_results=max_results,\n",
    "                page=page,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Normalize result structure\n",
    "        normalized = []\n",
    "        for i, r in enumerate(results):\n",
    "            normalized.append({\n",
    "                \"id\": i,\n",
    "                \"title\": r.get(\"title\"),\n",
    "                \"url\": r.get(\"href\"),\n",
    "                \"snippet\": r.get(\"body\"),\n",
    "            })\n",
    "\n",
    "        return normalized\n",
    "\n",
    "    def fetch(self, url: str):\n",
    "        \"\"\"\n",
    "        Fetch a webpage and return Markdown.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            html = response.text\n",
    "\n",
    "            # Convert HTML â†’ Markdown\n",
    "            markdown = html_to_md(html)\n",
    "\n",
    "            cleaned = clean_text(markdown)\n",
    "            return cleaned[:20000]\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching page: {e}\"\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Autogen-Compatible Search Tool Wrapper\n",
    "# ----------------------------------------------------------------------\n",
    "class WebSearchTool:\n",
    "    def __init__(self, search_api):\n",
    "        self.api = search_api\n",
    "        self.current_query = None\n",
    "        self.current_page = 1\n",
    "        self.current_results = []\n",
    "\n",
    "        self.search_tool = FunctionTool(self.search, name=\"search_web\", description=self.search.__doc__)\n",
    "        self.select_tool = FunctionTool(self.select_webpage, name=\"open_webpage\", description=self.select_webpage.__doc__)\n",
    "        self.next_page_tool = FunctionTool(self.next_page, name=\"next_search_page\", description=self.next_page.__doc__)\n",
    "\n",
    "    # ------------------- TOOLS -------------------\n",
    "\n",
    "    async def search(self, query: str, page: int = 1):\n",
    "        \"\"\"Perform Web Search using DuckDuckGo.\"\"\"\n",
    "        self.current_query = query\n",
    "        self.current_page = page\n",
    "        self.current_results = self.api.search(query, page)\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"page\": page,\n",
    "            \"results\": self.current_results\n",
    "        }\n",
    "\n",
    "    async def select_webpage(self, result_id: int):\n",
    "        \"\"\"Fetch selected webpage content.\"\"\"\n",
    "        if not self.current_results:\n",
    "            return {\"error\": \"No active search results\"}\n",
    "\n",
    "        if result_id < 0 or result_id >= len(self.current_results):\n",
    "            return {\"error\": \"Invalid result_id\"}\n",
    "\n",
    "        url = self.current_results[result_id][\"url\"]\n",
    "        content = self.api.fetch(url)\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"content\": content\n",
    "        }\n",
    "\n",
    "    async def next_page(self):\n",
    "        \"\"\"Load the next page of DuckDuckGo search results.\"\"\"\n",
    "        if not self.current_query:\n",
    "            return {\"error\": \"No active query\"}\n",
    "\n",
    "        self.current_page += 1\n",
    "        self.current_results = self.api.search(self.current_query, self.current_page)\n",
    "\n",
    "        return {\n",
    "            \"query\": self.current_query,\n",
    "            \"page\": self.current_page,\n",
    "            \"results\": self.current_results\n",
    "        }\n",
    "\n",
    "    def get_tools(self):\n",
    "        return [\n",
    "            self.search_tool,\n",
    "            self.select_tool,\n",
    "            self.next_page_tool\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2af1be6-fb13-45b0-bc3e-3d8c04a155c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_api = DuckDuckGoAPI()\n",
    "web_tools = WebSearchTool(duck_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25c90f00-64ea-4df4-9872-d42e36ebe347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Diffusion LLM',\n",
       " 'page': 1,\n",
       " 'results': [{'id': 0,\n",
       "   'title': '[2502.09992] Large Language Diffusion Models - arXiv.org',\n",
       "   'url': 'https://arxiv.org/abs/2502.09992',\n",
       "   'snippet': 'A diffusion model trained from scratch that models distributions through a forward and reverse process, parameterized by a Transformer. It outperforms autoregressive models on various benchmarks and shows strong in-context learning and instruction-following abilities.'},\n",
       "  {'id': 1,\n",
       "   'title': 'Inception Labs banks $50M to make diffusion LLMs 10x faster',\n",
       "   'url': 'https://techfundingnews.com/inception-labs-banks-50m-to-make-diffusion-llms-10x-faster/',\n",
       "   'snippet': \"Inception's flagship model, Mercury, is the world's first commercially available diffusion LLM . It outpaces even speed-optimised models from OpenAI, Anthropic, and Google by 5-10x, while matching their precision. Mercury comes in two versions: a general-purpose model for conversational tasks and Mercury Coder, tuned for code generation.\"},\n",
       "  {'id': 2,\n",
       "   'title': 'Diffusion LLMs: A New Era of Large Language Models',\n",
       "   'url': 'https://markovate.com/diffusion-llms/',\n",
       "   'snippet': 'Explore the rise of Diffusion LLMs , a fresh concept in the AI market that sets itself apart from traditional models.'},\n",
       "  {'id': 3,\n",
       "   'title': 'Diffusion LLMs: The Future of Language Models or Hype?',\n",
       "   'url': 'https://www.golan.ai/ai-news/diffusion-llms-the-future-of-language-models-or-hype-0B9EMddwlOQ',\n",
       "   'snippet': 'Discover the power of Diffusion LLMs , a revolutionary new architecture that is poised to transform the world of large language models. Explore the impressive capabilities of Mercury, the first commercial-scale diffusion LLM , and learn how it can deliver lightning-fast token generation and exceptional performance on various benchmarks. This introduction-driven blog post offers a glimpse into ...'},\n",
       "  {'id': 4,\n",
       "   'title': 'The Next Step for dLLMs: Scaling up Mercury - Inception',\n",
       "   'url': 'https://www.inceptionlabs.ai/blog/mercury-refreshed',\n",
       "   'snippet': \"In February 2025, we launched our first model, Mercury, which is the first commercially available diffusion -based LLM (dLLM). Mercury is up to 10X faster and more efficient than today's LLMs while delivering best-in-class quality.\"},\n",
       "  {'id': 5,\n",
       "   'title': 'Diffusion based LLMs : The Next Frontier in Language AI',\n",
       "   'url': 'https://aininza.substack.com/p/diffusion-based-llms-the-next-frontier',\n",
       "   'snippet': 'The open-source large language model ( LLM ) landscape has long been dominated by autoregressive (AR) models like Mistral 7B, Llama 3 8B, and Gemma 7B-models optimized for left-to-right generation. But a new challenger has emerged: diffusion -based LLMs like DreamLLM-7B, LLaDA, and Mercury Coder. These models rewrite the rules of text generation by creating entire responses simultaneously ...'},\n",
       "  {'id': 6,\n",
       "   'title': 'Diffusion LLMs: Rewriting the Rules of Language Generation',\n",
       "   'url': 'https://www.neilsahota.com/diffusion-llms-text-generation/',\n",
       "   'snippet': 'Diffusion -based LLMs are a new class of language models that generate text through denoising rather than predicting each token in sequence. Borrowing image and video generation techniques, they offer an alternative to the autoregressive architecture used by models like GPT.'},\n",
       "  {'id': 7,\n",
       "   'title': 'What Is a Diffusion LLM and Why Does It Matter? - HackerNoon',\n",
       "   'url': 'https://hackernoon.com/what-is-a-diffusion-llm-and-why-does-it-matter',\n",
       "   'snippet': 'What is diffusion large language model LLM , and why it matters. In the context of Inception Labs releasing Mercury Coder.'},\n",
       "  {'id': 8,\n",
       "   'title': 'What is Diffusion LLM and why it matters - Medium',\n",
       "   'url': 'https://medium.com/the-low-end-disruptor/what-is-diffusion-llm-and-why-it-matters-749033d1efb1',\n",
       "   'snippet': 'What is Diffusion LLM and why it matters Introduction Today Inception Labs released the first commercially available Diffusion Large Language Model (dLLM) â€” Mercury Coder, and caused a big stir â€¦'},\n",
       "  {'id': 9,\n",
       "   'title': 'Inception Lands $50M to Supercharge AI With Lightning-Fast Diffusion ...',\n",
       "   'url': 'https://martechedge.com/news/inception-lands-50m-to-supercharge-ai-with-lightning-fast-diffusion-llms',\n",
       "   'snippet': \"A New Phase of the LLM Race As enterprises demand faster, cheaper, and more interactive AI, diffusion LLMs could reshape what's possible. Autoregressive systems may still dominate today, but diffusion is emerging as the challenger technology with real commercial traction.\"}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await web_tools.search_tool.run_json({\"query\": \"Diffusion LLM\", \"page\":1}, CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71c66a9d-aed6-498c-b5d1-47b28f6f5a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = await web_tools.select_tool.run_json({\"result_id\": 1}, CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a51a5579-b497-45d8-9d42-a984ca569496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Labs banks $50M to make diffusion LLMs 10x faster â€” TFN\n",
      "\n",
      "[![Tech Funding News](https://techfundingnews.com/wp-content/uploads/2021/07/cropped-android-chrome-192x192-1.png)](https://techfundingnews.com/)\n",
      "[![Tech Funding News](https://techfundingnews.com/wp-content/uploads/2021/07/cropped-android-chrome-192x192-1.png)](https://techfundingnews.com/)\n",
      "\n",
      "* [UK](https://techfundingnews.com/category/uk/)\n",
      "* [Europe](https://techfundingnews.com/category/europe/)\n",
      "* [US](https://techfundingnews.com/category/us/)\n",
      "* [VC News](https://techfundingnews.com/category/vc/)\n",
      "* [Interviews](https://techfundingnews.com/category/interviews/)\n",
      "* [Partner Content](https://techfundingnews.com/category/sponsored/)\n",
      "* [AI News](https://techfundingnews.com/category/AI/)\n",
      "\n",
      "#### Subscribe TFN for Daily News Alerts\n",
      "\n",
      "Email address:\n",
      "\n",
      "By clicking submit, you agree to share your email address with TFN to receive marketing, updates, and other emails from the site owner. Use the unsubscribe link in the emails to opt out at any time.\n",
      "\n",
      "Leave this field empty if you're human:\n",
      "\n",
      "##### Categories\n",
      "\n",
      "* [Acquisition News](https://techfundingnews.com/category/acquisition/)\n",
      "* [Africa Tech News](https://techfundingnews.com/category/africa/)\n",
      "* [Agtech News](https://techfundingnews.com/category/agtech/)\n",
      "* [AI News](https://techfundingnews.com/category/ai/)\n",
      "* [App News](https://techfundingnews.com/category/app/)\n",
      "* [Asia Tech News](https://techfundingnews.com/category/asia/)\n",
      "* [Australia Tech News](https://techfundingnews.com/category/australia/)\n",
      "* [Autonomous News](https://techfundingnews.com/category/autonomous/)\n",
      "* [Batterytech News](https://techfundingnews.com/category/batterytech/)\n",
      "* [Biotech News](https://techfundingnews.com/category/biotech/)\n",
      "* [Blockchain News](https://techfundingnews.com/category/blockchain/)\n",
      "* [Blog](https://techfundingnews.com/category/blog/)\n",
      "* [BNPL News](https://techfundingnews.com/category/fintech/bnpl/)\n",
      "* [Business Wire](https://techfundingnews.com/category/business-wire/)\n",
      "* [Canada Tech News](https://techfundingnews.com/category/canada/)\n",
      "* [Challenger Bank News](https://techfundingnews.com/category/fintech/challenger-bank/)\n",
      "* [Climate Tech News](https://techfundingnews.com/category/climate-tech/)\n",
      "* [Cloud News](https://techfundingnews.com/category/cloud/)\n",
      "* [Covid-19 News](https://techfundingnews.com/category/covid-19/)\n",
      "* [Crypto News](https://techfundingnews.com/category/crypto/)\n",
      "* [Cybersecurity News](https://techfundingnews.com/category/cybersecurity/)\n",
      "* [Deeptech News](https://techfundingnews.com/category/deep-tech/)\n",
      "* [Defence Tech](https://techfundingnews.com/category/defence-tech/)\n",
      "* [Diversity News](https://techfundingnews.com/category/diversity/)\n",
      "* [Ecommerce News](https://techfundingnews.com/category/ecommerce/)\n",
      "* [Editor's Pick](https://techfundingnews.com/category/editors-pick/)\n",
      "* [Edtech News](https://techfundingnews.com/category/edtech/)\n",
      "* [Electric News](https://techfundingnews.com/category/electric/)\n",
      "* [Europe Tech News](https://techfundingnews.com/category/europe/)\n",
      "* [Female Funding](https://techfundingnews.com/category/female-funding/)\n",
      "* [Femtech News](https://techfundingnews.com/category/femtech/)\n",
      "* [Fintech News](https://techfundingnews.com/category/fintech/)\n",
      "* [Foodtech News](https://techfundingnews.com/category/foodtech/)\n",
      "* [Funding News](https://techfundingnews.com/category/funding/)\n",
      "* [Gadgets News](https://techfundingnews.com/category/gadgets/)\n",
      "* [Gaming News](https://techfundingnews.com/category/gaming/)\n",
      "* [Guest Post](https://techfundingnews.com/category/guest-post/)\n",
      "* [Healthtech News](https://techfundingnews.com/category/health/)\n",
      "* [HRtech News](https://techfundingnews.com/category/hrtech/)\n",
      "* [India Tech News](https://techfundingnews.com/category/india/)\n",
      "* [Interviews](https://techfundingnews.com/category/interviews/)\n",
      "* [Israel Tech News](https://techfundingnews.com/category/israel/)\n",
      "* [Latest News](https://techfundingnews.com/category/latest-news/)\n",
      "* [Marketplace News](https://techfundingnews.com/category/marketplace/)\n",
      "* [Medtech News](https://techfundingnews.com/category/medtech/)\n",
      "* [Middle East Tech News](https://techfundingnews.com/category/middle-east/)\n",
      "* [Mobility News](https://techfundingnews.com/category/mobility/)\n",
      "* [NFT News](https://techfundingnews.com/category/nft/)\n",
      "* [Other news](https://techfundingnews.com/category/other-news/)\n",
      "* [Partner Spotlight](https://techfundingnews.com/category/partner_spotlight/)\n",
      "* [Podcast](https://techfundingnews.com/category/podcast/)\n",
      "* [Popular now](https://techfundingnews.com/category/featured/)\n",
      "* [Premium](https://techfundingnews.com/category/premium/)\n",
      "* [Robotics News](https://techfundingnews.com/category/robotics/)\n",
      "* [SaaS News](https://techfundingnews.com/category/saas/)\n",
      "* [Social Media News](https://techfundingnews.com/category/social-media/)\n",
      "* [Spacetech News](https://techfundingnews.com/category/spacetech/)\n",
      "* [Sponsored](https://techfundingnews.com/category/sponsored-2/)\n",
      "* [Startups News](https://techfundingnews.com/category/startups/)\n",
      "* [Sustainable News](https://techfundingnews.com/category/sustainable/)\n",
      "* [TFN Partner Content](https://techfundingnews.com/category/sponsored/)\n",
      "* [Top Feature](https://techfundingnews.com/category/top-feature/)\n",
      "* [Top Funding Rounds](https://techfundingnews.com/category/top-funding-rounds/)\n",
      "* [Top News](https://techfundingnews.com/category/top-news/)\n",
      "* [Top Stories](https://techfundingnews.com/category/top-stories/)\n",
      "* [Traveltech News](https://techfundingnews.com/category/travel/)\n",
      "* [UK Tech News](https://techfundingnews.com/category/uk/)\n",
      "* [Unicorns](https://techfundingnews.com/category/unicorns/)\n",
      "* [US Tech News](https://techfundingnews.com/category/us/)\n",
      "* [VC News](https://techfundingnews.com/category/vc/)\n",
      "* [VR and AR News](https://techfundingnews.com/category/vr-and-ar/)\n",
      "* [WEB3 News](https://techfundingnews.com/category/web3/)\n",
      "* [Wellbeing News](https://techfundingnews.com/category/wellbeing/)\n",
      "\n",
      "[![Tech Funding News](https://techfundingnews.com/wp-content/uploads/2021/07/cropped-android-chrome-192x192-1.png)](https://techfundingnews.com/)\n",
      "[![Tech Funding News](https://techfundingnews.com/wp-content/uploads/2021/07/cropped-android-chrome-192x192-1.png)](https://techfundingnews.com/)\n",
      "\n",
      "* [UK](https://techfundingnews.com/category/uk/)\n",
      "* [Europe](https://techfundingnews.com/category/europe/)\n",
      "* [US](https://techfundingnews.com/category/us/)\n",
      "* [VC News](https://techfundingnews.com/category/vc/)\n",
      "* [Interviews](https://techfundingnews.com/category/interviews/)\n",
      "* [Partner Content](https://techfundingnews.com/category/sponsored/)\n",
      "* [AI News](https://techfundingnews.com/category/AI/)\n",
      "\n",
      "##### Gadgets\n",
      "\n",
      "* ![HiBob team](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAABQAQMAAAC032DuAAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABFJREFUKM9jYBgFo2AU0AsAAANwAAGRWmMdAAAAAElFTkSuQmCC)\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "### [8 best HR and payroll software for small teams in 2025](https://techfundingnews.com/8-best-hr-and-payroll-software-for-small-teams-in-2025/)\n",
      "\n",
      "[byEditorial team](https://techfundingnews.com/author/editorial-team/ \"View all posts by Editorial team\")\n",
      "* ![Grow Summit](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAABQAQMAAAC032DuAAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABFJREFUKM9jYBgFo2AU0AsAAANwAAGRWmMdAAAAAElFTkSuQmCC)\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "### [Londonâ€™s Grow Summit highlights founders at the frontier of innovation](https://techfundingnews.com/londons-grow-summit-highlights-founders-at-the-frontier-of-innovation/)\n",
      "\n",
      "[byJames Cousins](https://techfundingnews.com/author/james_cousins/ \"View all posts by James Cousins\")\n",
      "* ![Anysphere founders](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAABQAQMAAAC032DuAAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABFJREFUKM9jYBgFo2AU0AsAAANwAAGRWmMdAAAAAElFTkSuQmCC)\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "### [Anysphereâ€™s Cursor soars to $29B valuation with $2.3B round led by Accel, Coatue](https://techfundingnews.com/anysphere-soars-to-29-3b-valuation-with-2-3b-funding-redefining-the-future-of-coding/)\n",
      "\n",
      "[byAbhinaya Prabhu](https://techfundingnews.com/author/abhinaya_prabhu/ \"View all posts by Abhinaya Prabhu\")\n",
      "* ![Monty Munford, co-founder and acting CEO of HomeTruth](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAABQAQMAAAC032DuAAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABFJREFUKM9jYBgFo2AU0AsAAANwAAGRWmMdAAAAAElFTkSuQmCC)\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "### [Monty Munfordâ€™s HomeTruth hits $4M valuation to disrupt home insurance and finance](https://techfundingnews.com/hometruth-lands-4m-valuation-as-it-targets-a-fairer-future-for-homeowners/)\n",
      "\n",
      "[byAbhinaya Prabhu](https://techfundingnews.com/author/abhinaya_prabhu/ \"View all posts by Abhinaya Prabhu\")\n",
      "* ![Funding](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAABQAQMAAAC032DuAAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABFJREFUKM9jYBgFo2AU0AsAAANwAAGRWmMdAAAAAElFTkSuQmCC)\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "### [Funding the future: How grants are fueling school security innovation](https://techfundingnews.com/funding-the-future-how-grants-are-fueling-school-security-innovation/)\n",
      "\n",
      "[byEditorial team](https://techfundingnews.com/author/editorial-team/ \"View all posts by Editorial team\")\n",
      "\n",
      "NEWSLETTER\n",
      "\n",
      "Email address:\n",
      "\n",
      "By clicking submit, you agree to share your email address with TFN to receive marketing, updates, and other emails from the site owner. Use the unsubscribe link in the emails to opt out at any time.\n",
      "\n",
      "Leave this field empty if you're human:\n",
      "\n",
      "[![Tech Funding News](https://techfundingnews.com/wp-content/uploads/2021/07/cropped-android-chrome-192x192-1.png)](https://techfundingnews.com/)\n",
      "[![Tech Funding News](https://techfundingnews.com/wp-content/uploads/2021/07/cropped-android-chrome-192x192-1.png)](https://techfundingnews.com/)\n",
      "\n",
      "##### The Latest\n",
      "\n",
      "![HiBob team](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG4AAABuAQMAAAD8lbS4AAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABVJREFUOMtjYBgFo2AUjIJRMAroAQAGcgABdoTxvAAAAABJRU5ErkJggg==)\n",
      "\n",
      "###### [8 best HR and payroll software for small teams in 2025](https://techfundingnews.com/8-best-hr-and-payroll-software-for-small-teams-in-2025/)\n",
      "\n",
      "* [HRtech News](https://techfundingnews.com/category/hrtech/)\n",
      "* [Latest News](https://techfundingnews.com/category/latest-news/)\n",
      "* [Sponsored](https://techfundingnews.com/category/sponsored-2/)\n",
      "* [Startups News](https://techfundingnews.com/category/startups/)\n",
      "* [TFN Partner Content](https://techfundingnews.com/category/sponsored/)\n",
      "\n",
      "[byEditorial team](https://techfundingnews.com/author/editorial-team/ \"View all posts by Editorial team\")\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "7 minute read\n",
      "\n",
      "![Grow Summit](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG4AAABuAQMAAAD8lbS4AAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABVJREFUOMtjYBgFo2AUjIJRMAroAQAGcgABdoTxvAAAAABJRU5ErkJggg==)\n",
      "\n",
      "###### [Londonâ€™s Grow Summit highlights founders at the frontier of innovation](https://techfundingnews.com/londons-grow-summit-highlights-founders-at-the-frontier-of-innovation/)\n",
      "\n",
      "* [Diversity News](https://techfundingnews.com/category/diversity/)\n",
      "* [Editor's Pick](https://techfundingnews.com/category/editors-pick/)\n",
      "* [Interviews](https://techfundingnews.com/category/interviews/)\n",
      "* [Latest News](https://techfundingnews.com/category/latest-news/)\n",
      "* [Popular now](https://techfundingnews.com/category/featured/)\n",
      "* [Sponsored](https://techfundingnews.com/category/sponsored-2/)\n",
      "* [TFN Partner Content](https://techfundingnews.com/category/sponsored/)\n",
      "* [Top News](https://techfundingnews.com/category/top-news/)\n",
      "* [Top Stories](https://techfundingnews.com/category/top-stories/)\n",
      "* [UK Tech News](https://techfundingnews.com/category/uk/)\n",
      "\n",
      "[byJames Cousins](https://techfundingnews.com/author/james_cousins/ \"View all posts by James Cousins\")\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "5 minute read\n",
      "\n",
      "![Anysphere founders](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG4AAABuAQMAAAD8lbS4AAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABVJREFUOMtjYBgFo2AUjIJRMAroAQAGcgABdoTxvAAAAABJRU5ErkJggg==)\n",
      "\n",
      "###### [Anysphereâ€™s Cursor soars to $29B valuation with $2.3B round led by Accel, Coatue](https://techfundingnews.com/anysphere-soars-to-29-3b-valuation-with-2-3b-funding-redefining-the-future-of-coding/)\n",
      "\n",
      "* [AI News](https://techfundingnews.com/category/ai/)\n",
      "* [Funding News](https://techfundingnews.com/category/funding/)\n",
      "* [Latest News](https://techfundingnews.com/category/latest-news/)\n",
      "* [Popular now](https://techfundingnews.com/category/featured/)\n",
      "* [Startups News](https://techfundingnews.com/category/startups/)\n",
      "* [Top Funding Rounds](https://techfundingnews.com/category/top-funding-rounds/)\n",
      "* [Top News](https://techfundingnews.com/category/top-news/)\n",
      "* [Top Stories](https://techfundingnews.com/category/top-stories/)\n",
      "* [Unicorns](https://techfundingnews.com/category/unicorns/)\n",
      "* [US Tech News](https://techfundingnews.com/category/us/)\n",
      "\n",
      "[byAbhinaya Prabhu](https://techfundingnews.com/author/abhinaya_prabhu/ \"View all posts by Abhinaya Prabhu\")\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "2 minute read\n",
      "\n",
      "![Monty Munford, co-founder and acting CEO of HomeTruth](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG4AAABuAQMAAAD8lbS4AAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAABVJREFUOMtjYBgFo2AUjIJRMAroAQAGcgABdoTxvAAAAABJRU5ErkJggg==)\n",
      "\n",
      "###### [Monty Munfordâ€™s HomeTruth hits $4M valuation to disrupt home insurance and finance](https://techfundingnews.com/hometruth-lands-4m-valuation-as-it-targets-a-fairer-future-for-homeowners/)\n",
      "\n",
      "* [Funding News](https://techfundingnews.com/category/funding/)\n",
      "* [Latest News](https://techfundingnews.com/category/latest-news/)\n",
      "* [Popular now](https://techfundingnews.com/category/featured/)\n",
      "* [Startups News](https://techfundingnews.com/category/startups/)\n",
      "* [Top News](https://techfundingnews.com/category/top-news/)\n",
      "* [Top Stories](https://techfundingnews.com/category/top-stories/)\n",
      "* [UK Tech News](https://techfundingnews.com/category/uk/)\n",
      "\n",
      "[byAbhinaya Prabhu](https://techfundingnews.com/author/abhinaya_prabhu/ \"View all posts by Abhinaya Prabhu\")\n",
      "\n",
      "November 14, 2025\n",
      "\n",
      "2 minute read\n",
      "\n",
      "* [Ð¸ÑˆÑ‰ÐµÑƒÑÑ€](https://techfundingnews.com/tag/%d0%b8%d1%88%d1%89%d0%b5%d1%83%d1%81%d1%80/)\n",
      "* [Ys](https://techfundingnews.com/tag/ys/)\n",
      "* [Yoni Assia](https://techfundingnews.com/tag/yoni-assia/)\n",
      "* [X](https://techfundingnews.com/tag/x/)\n",
      "* [WWDC](https://techfundingnews.com/tag/wwdc/)\n",
      "* [workertech](https://techfundingnews.com/tag/workertech/)\n",
      "* [women in tech](https://techfundingnews.com/tag/women-in-tech/)\n",
      "* [Woman in Tech](https://techfundingnews.com/tag/woman-in-tech/)\n",
      "* [Wise](https://techfundingnews.com/tag/wise/)\n",
      "* [wireless charging](https://techfundingnews.com/tag/wireless-charging/)\n",
      "\n",
      "* [AI News](https://techfundingnews.com/category/ai/)\n",
      "* [Funding News](https://techfundingnews.com/category/funding/)\n",
      "* [Latest News](https://techfundingnews.com/category/latest-news/)\n",
      "* [Popular now](https://techfundingnews.com/category/featured/)\n",
      "* [Startups News](https://techfundingnews.com/category/startups/)\n",
      "* [Top News](https://techfundingnews.com/category/top-news/)\n",
      "* [Top Stories](https://techfundingnews.com/category/top-stories/)\n",
      "* [US Tech News](https://techfundingnews.com/category/us/)\n",
      "\n",
      "Inception Labs banks $50M to make diffusion LLMs 10x faster\n",
      "===========================================================\n",
      "\n",
      "[![](https://secure.gravatar.com/avatar/96e0528549083f000d5340af7e95b0cccc4371c16f90f53837437398ffb2c8af?s=26&d=mm&r=g)byAbhinaya Prabhu](https://techfundingnews.com/author/abhinaya_prabhu/ \"View all posts by Abhinaya Prabhu\")\n",
      "\n",
      "November 7, 2025\n",
      "\n",
      "2 minute read\n",
      "\n",
      "![Inception Labs team](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAyAAAAGiAQMAAAAlWTDRAAAAA1BMVEUAAP+KeNJXAAAAAXRSTlMAQObYZgAAAAlwSFlzAAAOxAAADsQBlSsOGwAAAEBJREFUeNrtwTEBAAAAwqD1T20ND6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgH8DpOoAAZ94pL0AAAAASUVORK5CYII=)\n",
      "\n",
      "Image credits: Inception Labs\n",
      "\n",
      "Total\n",
      "\n",
      "0\n",
      "\n",
      "Shares\n",
      "\n",
      "[0](https://www.facebook.com/sharer.php?u=https://techfundingnews.com/inception-labs-banks-50m-to-make-diffusion-llms-10x-faster/)\n",
      "\n",
      "[0](https://twitter.com/share?&text=Inception%20Labs%20banks%20%2450M%20to%20make%20diffusion%20LLMs%2010x%20faster&via=TFNBreakingNews&url=https://techfundingnews.com/inception-labs-banks-50m-to-make-diffusion-llms-10x-faster/)\n",
      "\n",
      "[0](https://www.linkedin.com/shareArticle?mini=true&url=https://techfundingnews.com/inception-labs-banks-50m-to-make-diffusion-llms-10x-faster/)\n",
      "\n",
      "[0](whatsapp://send?text=https://techfundingnews.com/inception-labs-banks-50m-to-make-diffusion-llms-10x-faster/)\n",
      "\n",
      "Inception Labs AI, a Palo Altoâ€“based company pioneering diffusion-based large language models (dLLMs), has raised $50 million in fresh funding. The round was led by [Menlo Ventures](https://techfundingnews.com/us-vc-firm-menlo-ventures-closes-1-35b-fund-to-invest-in-ai-startups/), with participation from [Mayfield](https://techfundingnews.com/uber-alums-teambridge-secures-28m-to-manage-the-hourly-workforce/), Innovation Endeavors, [NVentures](https://techfundingnews.com/san-franciscos-exa-raises-85m-at-700m-valuation-to-build-the-search-engine-for-ai/) â€“ NVIDIAâ€™s venture arm, Microsoftâ€™s [M12](https://techfundingnews.com/female-founded-enterprise-tech-startup-deployed-rolls-4m-to-transform-the-language-of-project-planning-and-work-agreements/), [Snowflake Ventures](https://techfundingnews.com/snowflake-invests-in-115m-funding-round-of-observe-a-data-observability-startup/), and Databricks Investment.\n",
      "\n",
      "The funding will accelerate product development, expand research teams, and enhance real-time AI capabilities across text, voice, and code.\n",
      "\n",
      "### **The challenges it tackles**\n",
      "\n",
      "Most large language models today rely on autoregression, a method that generates words one at a time. While accurate, this sequential process is painfully slow and costly, making it difficult for enterprises to scale or deliver seamless real-time experiences.\n",
      "\n",
      "Inception takes a radically different approach. Its diffusion-based LLMs (dLLMs) borrow principles from image and video generation technologies such as DALLÂ·E, Midjourney, and Sora. Instead of crafting text word by word, dLLMs generate entire responses in parallel. This innovation delivers outputs that are 10x faster and far more efficient, without sacrificing coherence or accuracy.\n",
      "\n",
      "### **Mercury: Speed meets intelligence**\n",
      "\n",
      "Inceptionâ€™s flagship model, Mercury, is the worldâ€™s first commercially available diffusion LLM. It outpaces even speed-optimised models from [OpenAI](https://techfundingnews.com/openai-strikes-38b-deal-with-amazon-for-ai-cloud-services/), [Anthropic](https://techfundingnews.com/anthropic-10-billion-funding-openai-rival/), and Google by 5â€“10x, while matching their precision. Mercury comes in two versions: a general-purpose model for conversational tasks and Mercury Coder, tuned for code generation. Both feature a 128,000-token context window, equivalent to about 300 pages of text, allowing for deep and complex interactions.\n",
      "\n",
      "By drastically cutting GPU requirements, Inception enables organisations to run larger models at the same cost or serve more users using existing infrastructure. This makes Mercury ideal for latency-sensitive applications such as live voice assistants, dynamic UIs, and real-time programming tools, areas where speed defines usability.\n",
      "\n",
      "### **Inventors of a new language era**\n",
      "\n",
      "Inception Labs AI was co-founded by [Stefano Ermon](https://www.linkedin.com/in/ermon), [Aditya Grover](https://www.linkedin.com/in/aditya-grover), and [Volodymyr Kuleshov](https://www.linkedin.com/in/volodymyr-kuleshov-6aa83294) in 2024 in Palo Alto, California. The founding trio, who have roots at Stanford, UCLA, and Cornell, were among the early researchers behind core AI advances such as diffusion, flash attention, and direct preference optimisation. CEO Stefano Ermon is also a co-inventor of the diffusion techniques that power systems like Midjourney and [OpenAIâ€™s Sora](https://techfundingnews.com/openais-sora-on-the-rise-inside-sam-altmans-7-trillion-ai-investment-quest/).\n",
      "\n",
      "Beyond spee\n"
     ]
    }
   ],
   "source": [
    "print(results[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cbb2054-6298-4616-ad0a-ca8d9e7e490a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Diffusion LLM',\n",
       " 'page': 2,\n",
       " 'results': [{'id': 0,\n",
       "   'title': 'arXiv [2506.17298] Mercury: Ultra-Fast Language Models Based on Diffusion',\n",
       "   'url': 'https://arxiv.org/abs/2506.17298',\n",
       "   'snippet': 'June 17, 2025 - View a PDF of the paper titled Mercury: Ultra-Fast Language Models Based on Diffusion , by Inception Labs and 12 other authors View PDF HTML (experimental) Abstract:We present Mercury, a new generation of commercial-scale large language models (LLMs) based on diffusion .'},\n",
       "  {'id': 1,\n",
       "   'title': 'Simon Willison Gemini Diffusion',\n",
       "   'url': 'https://simonwillison.net/2025/May/21/gemini-diffusion/',\n",
       "   'snippet': \"May 21, 2025 - Another of the announcements from Google I/O yesterday was Gemini Diffusion , Google's first LLM to use diffusion (similar to image models like Imagen and Stable Diffusion ) in place of transformers. â€¦\"},\n",
       "  {'id': 2,\n",
       "   'title': 'IBM Diffusion models challenge GPT as next-generation AI emerges | IBM',\n",
       "   'url': 'https://www.ibm.com/think/news/diffusion-models-llms',\n",
       "   'snippet': 'April 18, 2025 - Inception Labs, a startup founded by researchers from Stanford, recently released Mercury, a diffusion -based language model (dLLM) that refines entire phrases at once, rather than predicting words one by one. Unlike traditional large language models (LLMs), which use an autoregressive ...'},\n",
       "  {'id': 3,\n",
       "   'title': 'arXiv [2508.10875] A Survey on Diffusion Language Models',\n",
       "   'url': 'https://arxiv.org/abs/2508.10875',\n",
       "   'snippet': 'August 14, 2025 - Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising alternative to the dominant autoregressive (AR) paradigm. By generating tokens in parallel through an iterative denoising process, DLMs possess inherent advantages in reducing inference latency and capturing ...'},\n",
       "  {'id': 4,\n",
       "   'title': 'Hacker News Mercury Coder: frontier diffusion LLM generating 1000+ tok/sec on commodity GPUs | Hacker News',\n",
       "   'url': 'https://news.ycombinator.com/item?id=43187518',\n",
       "   'snippet': 'March 7, 2025 - The moment I heard the synopsis of the technique, I thought of one thing: Style transfer Â· This model style should be really nice for translation and style transfer tasks. Takes an existing section text, noises it, and reverses it with guidance like an image diffusion model; A \"movement\" in ...'},\n",
       "  {'id': 5,\n",
       "   'title': 'HackerNoon What Is a Diffusion LLM and Why Does It Matter? | HackerNoon',\n",
       "   'url': 'https://hackernoon.com/what-is-a-diffusion-llm-and-why-does-it-matter',\n",
       "   'snippet': 'March 1, 2025 - What is diffusion large language model LLM , and why it matters. In the context of Inception Labs releasing Mercury Coder.'},\n",
       "  {'id': 6,\n",
       "   'title': 'Medium Diffusion LLM // Finally it is working | by noailabs | Medium',\n",
       "   'url': 'https://noailabs.medium.com/diffusion-llm-finally-it-is-working-4e19c0204f7c',\n",
       "   'snippet': 'February 27, 2025 - Diffusion LLM // Finally it is working Diffusion approach is used for images, video, and music // now hacked for text and code Actually data is a key, models are just wrappers | compressors | â€¦'},\n",
       "  {'id': 7,\n",
       "   'title': 'GitHub [Feature]: Support for diffusion LLM models like LLADA Â· Issue #18532 Â· vllm-project/vllm',\n",
       "   'url': 'https://github.com/vllm-project/vllm/issues/18532',\n",
       "   'snippet': 'May 22, 2025 - ðŸš€ The feature, motivation and pitch Hi, I was wondering if support for diffusion models is possible with VLLM. With the launch of gemini diffusion models, I think the future would involve llm diffu...'},\n",
       "  {'id': 8,\n",
       "   'title': 'Neil Sahota Diffusion LLMs: Rewriting the Rules of Language Generation Â· Neil Sahota',\n",
       "   'url': 'https://www.neilsahota.com/diffusion-llms-text-generation/',\n",
       "   'snippet': 'June 5, 2025 - Most large language models (LLMs) follow a familiar design: theyâ€™re built using autoregressive training, which means they generate text by predicting one word or part of a word (a token) at a time in a strict left-to-right sequence. Diffusion LLMs skip the step-by-step process.'},\n",
       "  {'id': 9,\n",
       "   'title': 'arXiv [2504.12216] d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning',\n",
       "   'url': 'https://arxiv.org/abs/2504.12216',\n",
       "   'snippet': 'June 3, 2025 - Although recent diffusion -based large language models (dLLMs) have achieved competitive language modeling performance compared to their AR counterparts, it remains unclear if dLLMs can also leverage recent advances in LLM reasoning. To this end, we propose d1, a framework to adapt pre-trained ...'}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await web_tools.next_page_tool.run_json({}, CancellationToken())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bb718-6f37-47cd-a8fd-69868d76584a",
   "metadata": {},
   "source": [
    "# Arxiv tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a2e0f83-3203-4e88-963e-722516f7870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.tools import FunctionTool\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from markdownify import markdownify as html_to_md\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "import io\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Text Normalization Helper\n",
    "# ------------------------------------------------------------\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean and normalize extracted text.\n",
    "\n",
    "    Operations performed:\n",
    "    - Remove tab characters.\n",
    "    - Collapse 3 or more consecutive newlines into exactly 2.\n",
    "    - Collapse multiple consecutive spaces into one.\n",
    "    - Strip leading/trailing whitespace from each line.\n",
    "    - Strip whitespace at the document edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Raw text extracted from PDF or HTML.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Cleaned, compact, readable text.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\" {2,}\", \" \", text)\n",
    "    text = \"\\n\".join(line.strip() for line in text.splitlines())\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PDF Content Reader â€” Provides Scrolling Windows\n",
    "# ------------------------------------------------------------\n",
    "class ArxivPaperReader:\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF and provides scrollable \"windows\" of content.\n",
    "\n",
    "    This allows an LLM agent to read a paper chunk-by-chunk, simulating\n",
    "    a scrolling browser window.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    window_size : int\n",
    "        Number of characters per window.\n",
    "    windows : list[str]\n",
    "        The split windows of text.\n",
    "    position : int\n",
    "        Current window index.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size_chars=3000):\n",
    "        \"\"\"\n",
    "        Initialize the reader.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        window_size_chars : int, optional\n",
    "            Maximum size of each scrolling window, by default 3000.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size_chars\n",
    "        self.windows = []\n",
    "        self.position = 0\n",
    "\n",
    "    def load_pdf(self, pdf_url: str) -> int:\n",
    "        \"\"\"\n",
    "        Download and parse a PDF from a URL, extract text, clean it,\n",
    "        and split into windows.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdf_url : str\n",
    "            Direct URL to the PDF.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of windows created.\n",
    "        \"\"\"\n",
    "        response = requests.get(pdf_url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        reader = PdfReader(io.BytesIO(response.content))\n",
    "        full_text = \"\"\n",
    "\n",
    "        for page in reader.pages:\n",
    "            extracted = page.extract_text() or \"\"\n",
    "            full_text += extracted + \"\\n\\n\"\n",
    "\n",
    "        full_text = clean_text(full_text)\n",
    "\n",
    "        self.windows = [\n",
    "            full_text[i:i + self.window_size]\n",
    "            for i in range(0, len(full_text), self.window_size)\n",
    "        ]\n",
    "        self.position = 0\n",
    "\n",
    "        return len(self.windows)\n",
    "\n",
    "    def get_window(self, index: int) -> str:\n",
    "        \"\"\"\n",
    "        Return a specific window of text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            Window index.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str or dict\n",
    "            Text of the window, or error dict if out of range.\n",
    "        \"\"\"\n",
    "        if index < 0 or index >= len(self.windows):\n",
    "            return {\"error\": \"Window index out of range\"}\n",
    "        return self.windows[index]\n",
    "\n",
    "    def next_window(self) -> str:\n",
    "        \"\"\"\n",
    "        Move to the next window.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str or dict\n",
    "            Next window text or error dict.\n",
    "        \"\"\"\n",
    "        if self.position + 1 >= len(self.windows):\n",
    "            return {\"error\": \"Already at last window\"}\n",
    "        self.position += 1\n",
    "        return self.get_window(self.position)\n",
    "\n",
    "    def prev_window(self) -> str:\n",
    "        \"\"\"\n",
    "        Move to the previous window.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str or dict\n",
    "            Previous window text or error dict.\n",
    "        \"\"\"\n",
    "        if self.position - 1 < 0:\n",
    "            return {\"error\": \"Already at first window\"}\n",
    "        self.position -= 1\n",
    "        return self.get_window(self.position)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ArXiv API Wrapper\n",
    "# ------------------------------------------------------------\n",
    "class ArxivAPI:\n",
    "    \"\"\"\n",
    "    A minimal wrapper around the ArXiv API, supporting searching\n",
    "    and extracting metadata needed to locate PDFs.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    search(query, page, max_results)\n",
    "        Perform a paginated ArXiv search.\n",
    "    \"\"\"\n",
    "\n",
    "    ARXIV_URL = \"http://export.arxiv.org/api/query\"\n",
    "\n",
    "    def search(self, query: str, page: int = 1, max_results: int = 10):\n",
    "        \"\"\"\n",
    "        Perform an ArXiv search using the official API.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query : str\n",
    "            Search query (e.g., \"machine learning\", \"cat:cs.CL\").\n",
    "        page : int, optional\n",
    "            Page number (converted into API 'start' parameter).\n",
    "        max_results : int, optional\n",
    "            Number of items per page.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[dict]\n",
    "            List of paper metadata dictionaries, each containing:\n",
    "            - id\n",
    "            - title\n",
    "            - authors\n",
    "            - summary\n",
    "            - pdf_url\n",
    "        \"\"\"\n",
    "        start = (page - 1) * max_results\n",
    "\n",
    "        params = {\"search_query\": query, \"start\": start, \"max_results\": max_results}\n",
    "        response = requests.get(self.ARXIV_URL, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        root = ET.fromstring(response.text)\n",
    "        ns = {\"atom\": \"http://www.w3.org/2005/Atom\"}\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for i, entry in enumerate(root.findall(\"atom:entry\", ns)):\n",
    "            title = entry.find(\"atom:title\", ns).text.strip()\n",
    "            summary = entry.find(\"atom:summary\", ns).text.strip()\n",
    "            authors = [a.find(\"atom:name\", ns).text.strip()\n",
    "                       for a in entry.findall(\"atom:author\", ns)]\n",
    "\n",
    "            # Extract PDF link\n",
    "            pdf_url = None\n",
    "            for link in entry.findall(\"atom:link\", ns):\n",
    "                if link.attrib.get(\"title\") == \"pdf\":\n",
    "                    pdf_url = link.attrib[\"href\"]\n",
    "\n",
    "            if not pdf_url:\n",
    "                id_url = entry.find(\"atom:id\", ns).text\n",
    "                pdf_url = id_url.replace(\"abs\", \"pdf\")\n",
    "\n",
    "            results.append({\n",
    "                \"id\": i,\n",
    "                \"title\": title,\n",
    "                \"authors\": authors,\n",
    "                \"summary\": summary,\n",
    "                \"pdf_url\": pdf_url,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Autogen-Compatible Tool Wrapper\n",
    "# ------------------------------------------------------------\n",
    "class ArxivSearchTool:\n",
    "    \"\"\"\n",
    "    Provides an Autogen FunctionTool interface for:\n",
    "    - ArXiv search\n",
    "    - Opening a paper\n",
    "    - Scrolling through PDF content in windows\n",
    "    - Changing pages of search results\n",
    "\n",
    "    This class is designed to be plugged directly into an Autogen agent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api: ArxivAPI, window_size_chars: int = 3000):\n",
    "        \"\"\"\n",
    "        Initialize the tool.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        api : ArxivAPI\n",
    "            Backend API used for searching.\n",
    "        window_size_chars : int, optional\n",
    "            Size of PDF text windows for scrolling.\n",
    "        \"\"\"\n",
    "        self.api = api\n",
    "        self.current_query = None\n",
    "        self.current_page = 1\n",
    "        self.current_results = []\n",
    "\n",
    "        # Reader for opened PDFs\n",
    "        self.reader = ArxivPaperReader(window_size_chars)\n",
    "\n",
    "        # Tools exposed to Autogen\n",
    "        self.search_tool = FunctionTool(self.search, name=\"search_arxiv\", description=self.search.__doc__)\n",
    "        self.select_tool = FunctionTool(self.open_paper, name=\"open_paper\", description=self.open_paper.__doc__)\n",
    "        self.next_win_tool = FunctionTool(self.next_window, name=\"next_window\", description=self.next_window.__doc__)\n",
    "        self.prev_win_tool = FunctionTool(self.prev_window, name=\"prev_window\", description=self.prev_window.__doc__)\n",
    "        self.go_win_tool = FunctionTool(self.get_window, name=\"read_window\", description=self.get_window.__doc__)\n",
    "        self.next_page_tool = FunctionTool(self.next_page, name=\"next_arxiv_page\", description=self.next_page.__doc__)\n",
    "\n",
    "    # ------------------- SEARCH -------------------\n",
    "\n",
    "    def search(self, query: str, page: int = 1):\n",
    "        \"\"\"\n",
    "        Search ArXiv and store results.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query : str\n",
    "            Search keyword or category.\n",
    "        page : int, optional\n",
    "            Page number to fetch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Search metadata including results list.\n",
    "        \"\"\"\n",
    "        self.current_query = query\n",
    "        self.current_page = page\n",
    "        self.current_results = self.api.search(query, page)\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"page\": page,\n",
    "            \"results\": self.current_results\n",
    "        }\n",
    "\n",
    "    # ------------------- OPEN PAPER + LOAD PDF -------------------\n",
    "\n",
    "    def open_paper(self, result_id: int):\n",
    "        \"\"\"\n",
    "        Open a paper by ID from the current search results,\n",
    "        download the PDF, extract text, and create windows.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        result_id : int\n",
    "            Index of the paper in current results.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Paper metadata and first window of content.\n",
    "        \"\"\"\n",
    "        if not self.current_results:\n",
    "            return {\"error\": \"No active search results.\"}\n",
    "\n",
    "        if result_id < 0 or result_id >= len(self.current_results):\n",
    "            return {\"error\": \"Invalid result_id.\"}\n",
    "\n",
    "        paper = self.current_results[result_id]\n",
    "        pdf_url = paper[\"pdf_url\"]\n",
    "\n",
    "        num_windows = self.reader.load_pdf(pdf_url)\n",
    "\n",
    "        return {\n",
    "            \"title\": paper[\"title\"],\n",
    "            \"authors\": paper[\"authors\"],\n",
    "            \"total_windows\": num_windows,\n",
    "            \"first_window\": self.reader.get_window(0)\n",
    "        }\n",
    "\n",
    "    # ------------------- WINDOW CONTROLS -------------------\n",
    "\n",
    "    def next_window(self):\n",
    "        \"\"\"\n",
    "        Move forward one window in the opened paper.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str or dict\n",
    "            Window text or error dictionary.\n",
    "        \"\"\"\n",
    "        return self.reader.next_window()\n",
    "\n",
    "    def prev_window(self):\n",
    "        \"\"\"\n",
    "        Move backward one window in the opened paper.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str or dict\n",
    "            Window text or error dictionary.\n",
    "        \"\"\"\n",
    "        return self.reader.prev_window()\n",
    "\n",
    "    def get_window(self, index: int):\n",
    "        \"\"\"\n",
    "        Jump to a specific window.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            Window index.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str or dict\n",
    "            Window text or error dictionary.\n",
    "        \"\"\"\n",
    "        return self.reader.get_window(index)\n",
    "\n",
    "    # ------------------- SEARCH PAGE NAVIGATION -------------------\n",
    "\n",
    "    def next_page(self):\n",
    "        \"\"\"\n",
    "        Fetch the next page of search results for the current query.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            New search results.\n",
    "        \"\"\"\n",
    "        if not self.current_query:\n",
    "            return {\"error\": \"No active query\"}\n",
    "\n",
    "        self.current_page += 1\n",
    "        self.current_results = self.api.search(self.current_query, self.current_page)\n",
    "\n",
    "        return {\n",
    "            \"query\": self.current_query,\n",
    "            \"page\": self.current_page,\n",
    "            \"results\": self.current_results\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "331ae34c-c5fd-4f89-b244-c8e0a82116df",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ArxivAPI()\n",
    "arxiv_tools = ArxivSearchTool(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc224a65-f56e-4af6-b38c-378b6d473fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'diffusion llm',\n",
       " 'page': 1,\n",
       " 'results': [{'id': 0,\n",
       "   'title': 'DINGO: Constrained Inference for Diffusion LLMs',\n",
       "   'authors': ['Tarun Suresh',\n",
       "    'Debangshu Banerjee',\n",
       "    'Shubham Ugare',\n",
       "    'Sasa Misailovic',\n",
       "    'Gagandeep Singh'],\n",
       "   'summary': \"Diffusion LLMs have emerged as a promising alternative to conventional autoregressive LLMs, offering significant potential for improved runtime efficiency. However, existing diffusion models lack the ability to provably enforce user-specified formal constraints, such as regular expressions, which makes them unreliable for tasks that require structured outputs, such as fixed-schema JSON generation. Unlike autoregressive models that generate tokens sequentially, diffusion LLMs predict a block of tokens in parallel. This parallelism makes traditional constrained decoding algorithms, which are designed for sequential token prediction, ineffective at preserving the true output distribution. To address this limitation, we propose DINGO, a dynamic programming-based constrained decoding strategy that is both efficient and provably distribution-preserving. DINGO enables sampling of output strings with the highest probability under the model's predicted distribution, while strictly satisfying any user-specified regular expression. On standard symbolic math and JSON generation benchmarks, DINGO achieves up to a 68 percentage point improvement over unconstrained inference\",\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2505.23061v1'},\n",
       "  {'id': 1,\n",
       "   'title': 'Diffusion in LanCoIn3n+2 phases studied by perturbed angular correlation',\n",
       "   'authors': ['Randal Newhouse', 'Gary S. Collins'],\n",
       "   'summary': 'Jump frequencies of 111In/Cd tracer atoms were measured for a series of layered phases LanCoIn3n+2 using the technique of perturbed angular correlation of gamma rays (PAC). The frequencies were determined by analysis of nuclear quadrupole relaxation produced by fluctuating electric field gradients. Samples were synthesized having nominal values n= 1, 2, 3, 5 and \\\\infty, with n=\\\\infty corresponding to the L12 phase LaIn3. The phases form heuristically from LaIn3 by replacing every (n+1)th (100) mixed plane of La and In atoms with a plane of Co-atoms. For the n=1 phase, LaCoIn5, jump frequencies were too small to detect. Two signals were observed, one for indium atoms next to the Co-planes and the other for more distant indium atoms. No relaxation was observed for atoms next to the Co-planes, indicating that there is no diffusion across the Co-planes. With increasing n, jump rates for the other In-atoms increased toward values observed for LaIn3. Jump frequency activation enthalpies for n= 3 and 5 were observed to be the same as for n=\\\\infty, suggesting the same diffusion mechanism. However, the jump-frequency prefactors were found to be smaller for small n, which is attributed to reductions in the connectivity of the diffusion sublattice. We conclude that diffusion in the layered phases is remarkably similar to diffusion in LaIn3 once the reduced connectivity is taken into account.',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/1109.2262v1'},\n",
       "  {'id': 2,\n",
       "   'title': 'LLM-grounded Video Diffusion Models',\n",
       "   'authors': ['Long Lian',\n",
       "    'Baifeng Shi',\n",
       "    'Adam Yala',\n",
       "    'Trevor Darrell',\n",
       "    'Boyi Li'],\n",
       "   'summary': 'Text-conditioned diffusion models have emerged as a promising tool for neural video generation. However, current models still struggle with intricate spatiotemporal prompts and often generate restricted or incorrect motion. To address these limitations, we introduce LLM-grounded Video Diffusion (LVD). Instead of directly generating videos from the text inputs, LVD first leverages a large language model (LLM) to generate dynamic scene layouts based on the text inputs and subsequently uses the generated layouts to guide a diffusion model for video generation. We show that LLMs are able to understand complex spatiotemporal dynamics from text alone and generate layouts that align closely with both the prompts and the object motion patterns typically observed in the real world. We then propose to guide video diffusion models with these layouts by adjusting the attention maps. Our approach is training-free and can be integrated into any video diffusion model that admits classifier guidance. Our results demonstrate that LVD significantly outperforms its base video diffusion model and several strong baseline methods in faithfully generating videos with the desired attributes and motion patterns.',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2309.17444v3'},\n",
       "  {'id': 3,\n",
       "   'title': 'Diffusion in binary and pseudo-binary L12 indides, stannides, gallides and aluminides of rare-earth elements as studied using perturbed angular correlation of 111In/Cd',\n",
       "   'authors': ['Randal Newhouse', 'Justine Minish', 'Gary S. Collins'],\n",
       "   'summary': 'Diffusional jumps can produce fluctuating electric field gradients at nuclei of jumping atoms. Using perturbed angular correlation of gamma rays (PAC), jumps of probe atoms cause nuclear quadrupole relaxation that can be fitted to obtain the mean jump frequency. An overview is given of the application of this approach to highly ordered intermetallic compounds having the L12 (Cu3Au) crystal structure. New results are then presented for jump frequencies of 111In/Cd probe atoms in pseudo-binary L12 compounds of the forms In3(La1-xPrx) and (In1-xSnx)3La. For the mixed rare-earth system, jump frequencies are found to scale with composition between jump frequencies of the end-member phases In3La and In3Pr. However, for the mixed sp-element system, a large decrease in jump frequency is observed as Sn atoms substitute for In-atoms. This difference in behavior appears to depend on whether atomic disorder is on the diffusion sublattice (In-Sn substitution), as opposed to a neighboring sublattice (La-Pr substitution), whether or not there is a difference in diffusion mechanism between end-member phases, and/or whether or not there is a valence difference between the mixing atoms. All three conditions apply for only (In1-xSnx)3La.',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/1109.2261v1'},\n",
       "  {'id': 4,\n",
       "   'title': 'RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit',\n",
       "   'authors': ['Jiongnan Liu',\n",
       "    'Jiajie Jin',\n",
       "    'Zihan Wang',\n",
       "    'Jiehan Cheng',\n",
       "    'Zhicheng Dou',\n",
       "    'Ji-Rong Wen'],\n",
       "   'summary': 'Although Large Language Models (LLMs) have demonstrated extraordinary capabilities in many domains, they still have a tendency to hallucinate and generate fictitious responses to user requests. This problem can be alleviated by augmenting LLMs with information retrieval (IR) systems (also known as retrieval-augmented LLMs). Applying this strategy, LLMs can generate more factual texts in response to user input according to the relevant content retrieved by IR systems from external corpora as references. In addition, by incorporating external knowledge, retrieval-augmented LLMs can answer in-domain questions that cannot be answered by solely relying on the world knowledge stored in parameters. To support research in this area and facilitate the development of retrieval-augmented LLM systems, we develop RETA-LLM, a {RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline to help researchers and users build their customized in-domain LLM-based systems. Compared with previous retrieval-augmented LLM systems, RETA-LLM provides more plug-and-play modules to support better interaction between IR systems and LLMs, including {request rewriting, document retrieval, passage extraction, answer generation, and fact checking} modules. Our toolkit is publicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2306.05212v1'},\n",
       "  {'id': 5,\n",
       "   'title': 'Analyzing PFG anisotropic anomalous diffusions by instantaneous signal attenuation method',\n",
       "   'authors': ['Guoxing Lin'],\n",
       "   'summary': 'Anomalous diffusion has been investigated in many systems. Pulsed field gradient (PFG) anomalous diffusion is much more complicated than PFG normal diffusion. There have been many theoretical and experimental studies for PFG isotropic anomalous diffusion, but there are very few theoretical treatments reported for anisotropic anomalous diffusion. Currently, there is not a general PFG signal attenuation expression, which includes the finite gradient pulse effect and can treat all three types of anisotropic fractional diffusions: general fractional diffusion, time fractional diffusion, and space-fractional diffusion. In this paper, the recently developed instantaneous signal attenuation (ISA) method was applied to obtain PFG signal attenuation expression for free and restricted anisotropic anomalous diffusion with two models: fractal derivative and fractional derivative models. The obtained PFG signal attenuation expression for anisotropic anomalous diffusion can reduce to the reported result for PFG anisotropic normal diffusion. The results can also reduce to reported PFG isotropic anomalous diffusion results obtained by effective phase shift diffusion equation method and instantaneous signal attenuation method. For anisotropic space-fractional diffusion, the obtained result agrees with that obtained by the modified Bloch equation method. Additionally, The PFG signal attenuation expressions for free and restricted anisotropic curvilinear diffusions were derived by the traditional method, the results of which agree with the PFG anisotropic fractional diffusion results based on the fractional derivative model. The powder pattern of PFG anisotropic diffusion was also discussed. The results here improve our understanding of PFG anomalous diffusion, and provide new formalisms for PFG anisotropic anomalous diffusion in NMR and MRI.',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/1701.00257v2'},\n",
       "  {'id': 6,\n",
       "   'title': 'FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation',\n",
       "   'authors': ['Liqun Ma', 'Mingjie Sun', 'Zhiqiang Shen'],\n",
       "   'summary': 'This work presents a Fully BInarized Large Language Model (FBI-LLM), demonstrating for the first time how to train a large-scale binary language model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to match the performance of its full-precision counterparts (e.g., FP16 or BF16) in transformer-based LLMs. It achieves this by employing an autoregressive distillation (AD) loss with maintaining equivalent model dimensions (130M, 1.3B, 7B) and training data volume as regular LLM pretraining, while delivering competitive results in terms of perplexity and task-specific effectiveness. Intriguingly, by analyzing the training trajectory, we find that the pretrained weight is not necessary for training binarized LLMs from scratch. This research encourages a new computational framework and may facilitate the future design of specialized hardware tailored for fully 1-bit LLMs. We make all models, code, and training dataset fully accessible and transparent to support further research (Code: https://github.com/LiqunMa/FBI-LLM. Model: https://huggingface.co/LiqunMa/).',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2407.07093v1'},\n",
       "  {'id': 7,\n",
       "   'title': 'Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates',\n",
       "   'authors': ['Hui Wei',\n",
       "    'Shenghua He',\n",
       "    'Tian Xia',\n",
       "    'Fei Liu',\n",
       "    'Andy Wong',\n",
       "    'Jingyang Lin',\n",
       "    'Mei Han'],\n",
       "   'summary': \"LLM-as-a-Judge has been widely applied to evaluate and compare different LLM alignmnet approaches (e.g., RLHF and DPO). However, concerns regarding its reliability have emerged, due to LLM judges' biases and inconsistent decision-making. Previous research has developed evaluation frameworks to assess reliability of LLM judges and their alignment with human preferences. However, the employed evaluation metrics often lack adequate explainability and fail to address LLM internal inconsistency. Additionally, existing studies inadequately explore the impact of various prompt templates when applying LLM-as-a-Judge methods, leading to potentially inconsistent comparisons between different alignment algorithms. In this work, we systematically evaluate LLM-as-a-Judge on alignment tasks by defining more theoretically interpretable evaluation metrics and explicitly mitigating LLM internal inconsistency from reliability metrics. We develop an open-source framework to evaluate, compare, and visualize the reliability and alignment of LLM judges, which facilitates practitioners to choose LLM judges for alignment tasks. In the experiments, we examine effects of diverse prompt templates on LLM-judge reliability and also demonstrate our developed framework by comparing various LLM judges on two common alignment datasets (i.e., TL;DR Summarization and HH-RLHF-Helpfulness). Our results indicate a significant impact of prompt templates on LLM judge performance, as well as a mediocre alignment level between the tested LLM judges and human evaluators.\",\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2408.13006v2'},\n",
       "  {'id': 8,\n",
       "   'title': 'Demystifying AI Platform Design for Distributed Inference of Next-Generation LLM models',\n",
       "   'authors': ['Abhimanyu Bambhaniya',\n",
       "    'Ritik Raj',\n",
       "    'Geonhwa Jeong',\n",
       "    'Souvik Kundu',\n",
       "    'Sudarshan Srinivasan',\n",
       "    'Suvinay Subramanian',\n",
       "    'Midhilesh Elavazhagan',\n",
       "    'Madhu Kumar',\n",
       "    'Tushar Krishna'],\n",
       "   'summary': 'Large language models (LLMs) have shown remarkable performance across a wide range of applications, often outperforming human experts. However, deploying these gigantic models efficiently for diverse inference use cases requires carefully designed hardware platforms with ample computing, memory, and network resources. With constant innovation in LLM serving optimizations and model architecture evolving at breakneck speed, the hardware requirements to meet Service Level Objectives (SLOs) remain an open research question.\\n  To answer the question, we present an analytical tool, GenZ, to efficiently navigate the relationship between diverse LLM model architectures(Dense, GQA, MoE, Mamba), LLM serving optimizations(Chunking, Speculative decoding, quanitization), and AI platform design parameters. Our tool estimates LLM inference performance metrics for the given scenario. We have validated against real hardware platforms running various different LLM models, achieving a max geomean error of 5.82.We use GenZ to identify compute, memory capacity, memory bandwidth, network latency, and network bandwidth requirements across diverse LLM inference use cases. We also study diverse architectural choices in use today (inspired by LLM serving platforms from several vendors) to help inform computer architects designing next-generation AI hardware accelerators and platforms. The trends and insights derived from GenZ can guide AI engineers deploying LLMs as well as computer architects designing next-generation hardware accelerators and platforms. Ultimately, this work sheds light on the platform design considerations for unlocking the full potential of large language models across a spectrum of applications. The source code is available at https://github.com/abhibambhaniya/GenZ-LLM-Analyzer . Users can also be tried it on at https://genz-llm-analyzer.streamlit.app/ without any setup on your web browser.',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2406.01698v3'},\n",
       "  {'id': 9,\n",
       "   'title': 'Can LLMs Lie? Investigation beyond Hallucination',\n",
       "   'authors': ['Haoran Huan',\n",
       "    'Mihir Prabhudesai',\n",
       "    'Mengning Wu',\n",
       "    'Shantanu Jaiswal',\n",
       "    'Deepak Pathak'],\n",
       "   'summary': 'Large language models (LLMs) have demonstrated impressive capabilities across a variety of tasks, but their increasing autonomy in real-world applications raises concerns about their trustworthiness. While hallucinations-unintentional falsehoods-have been widely studied, the phenomenon of lying, where an LLM knowingly generates falsehoods to achieve an ulterior objective, remains underexplored. In this work, we systematically investigate the lying behavior of LLMs, differentiating it from hallucinations and testing it in practical scenarios. Through mechanistic interpretability techniques, we uncover the neural mechanisms underlying deception, employing logit lens analysis, causal interventions, and contrastive activation steering to identify and control deceptive behavior. We study real-world lying scenarios and introduce behavioral steering vectors that enable fine-grained manipulation of lying tendencies. Further, we explore the trade-offs between lying and end-task performance, establishing a Pareto frontier where dishonesty can enhance goal optimization. Our findings contribute to the broader discourse on AI ethics, shedding light on the risks and potential safeguards for deploying LLMs in high-stakes environments. Code and more illustrations are available at https://llm-liar.github.io/',\n",
       "   'pdf_url': 'https://arxiv.org/pdf/2509.03518v1'}]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await arxiv_tools.search_tool.run_json({\"query\": \"diffusion llm\", \"page\":1}, CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24eabe10-f8cd-47f8-b39c-4367983889c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pypdf/_utils.py:262: ResourceWarning: unclosed <ssl.SSLSocket fd=71, family=2, type=1, proto=6, laddr=('172.18.0.2', 34364), raddr=('20.43.161.105', 443)>\n",
      "  m = regex.search(name + tok)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Diffusion in LanCoIn3n+2 phases studied by perturbed angular correlation',\n",
       " 'authors': ['Randal Newhouse', 'Gary S. Collins'],\n",
       " 'total_windows': 6,\n",
       " 'first_window': 'Diffusion in LanCoIn3n+2 phases studied by perturbed angular correlation\\nRandal Newhouse a and Gary S. Collins b\\nDepartment of Physics and Astronomy, Washington State University, Pullman, WA, USA\\narandynewhouse@gmail.com, bcollins@wsu.edu\\nKeywords: diffusion, perturbed angular correlation, PAC, hyperfine interaction, nuclear quadrupole\\ninteraction, atomic jump frequency, intermetallic compound.\\n\\nAbstract. Jump frequencies of 111In/Cd tracer atoms were measured for a series of layered phases\\nLanCoIn3n+2 using the technique of perturbed angular correlation of gamma rays (PAC). The\\nfrequencies were determined by analysis of nucl ear quadrupole relaxation produced by fluctuating\\nelectric field gradients. Samples were synthesized having nominal values n= 1, 2, 3, 5 and âˆž, with\\nn=âˆž corresponding to the L1 2 phase LaIn3. The phases form heuristically from LaIn 3 by replacing\\nevery (n+1)th (100) mixed plane of La and In atoms with a plane of Co-atoms. For the n=1 phase,\\nLaCoIn5, jump frequencies were too small to detect. Two signals were observed, one for indium\\natoms next to the Co-planes and the other for more distant indium atoms. No relaxation was\\nobserved for atoms next to the Co-planes, indicating that there is no diffusion across the Co-planes.\\nWith increasing n, jump rates for the other In-atoms in creased toward values observed for LaIn 3.\\nJump frequency activation enthalpies for n= 3 and 5 were observed to be the same as for n=âˆž,\\nsuggesting the same diffusion mechanism. However, the jump-frequency pref actors were found to\\nbe smaller for small n, which is attributed to reductions in the connectivity of the diffusion\\nsublattice. We conclude that diffusion in the la yered phases is remarkably similar to diffusion in\\nLaIn3 once the reduced connectivity is taken into account.\\nIntroduction\\nAtom-scale diffusion in solids can be detected through analysis of nuclear quadrupole relaxation\\nthat occurs when diffusional jumps lead to change s in magnitude or orientation of electric field\\ngradients (EFGs) at tracer nuclei. Perturbed an gular correlation of gamma rays (PAC) is a nuclear\\nhyperfine interaction method that has been applied to study such relaxation [1] using the 111In/Cd\\nprobe. The result of a measurement is a time-domain PAC perturbation function )(2 tG that, in\\neffect, exhibits quadrupole precessions of the 247 keV level of the daughter nuclide 111Cd.\\nStochastic fluctuations of EFGs lead to their averaging. Extensive studies have been made of\\nnuclear relaxation in compounds having the L1 2 structure using PAC [1, 2, 3, 4]. In that structure,\\nwhich has A3B stoichiometry, probe atoms jumping on the A-sublattice experience reorientations of\\nthe EFG from one [100] cube direction to another in each near-neighbor jump. In the slow-\\nfluctuation regime, when the average ju mp-frequency of the probe atom, w, is less than the\\nquadrupole interaction frequency, motional averag ing of the EFGs leads to decoherence of the\\nquadrupole perturbation function an'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await arxiv_tools.select_tool.run_json({\"result_id\": 1}, CancellationToken())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2668ea6-d7f2-4de0-a6a1-09b211025cc3",
   "metadata": {},
   "source": [
    "# defence tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee08139c-9925-47fe-90ef-b636da20c240",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'playwright'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmarkdownify\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m markdownify\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplaywright\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msync_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sync_playwright\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_markdown\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Normalize markdown whitespace.\"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'playwright'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_core.tools import FunctionTool\n",
    "from markdownify import markdownify\n",
    "import re\n",
    "from playwright.sync_api import sync_playwright\n",
    "\n",
    "\n",
    "def clean_markdown(text: str) -> str:\n",
    "    \"\"\"Normalize markdown whitespace.\"\"\"\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Playwright-backed TechCrunch search API\n",
    "# ----------------------------------------------------------------------\n",
    "class TechCrunchSearchAPI:\n",
    "    \"\"\"\n",
    "    Uses Playwright to load the TechCrunch site with JavaScript enabled\n",
    "    so that dynamic search results can be scraped.\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_URL = \"https://techcrunch.com/?s=\"\n",
    "\n",
    "    def __init__(self, headless: bool = True):\n",
    "        self.headless = headless\n",
    "\n",
    "    def _load_page(self, url: str):\n",
    "        \"\"\"Load a page using Playwright and return page object.\"\"\"\n",
    "        pw = sync_playwright().start()\n",
    "        browser = pw.chromium.launch(headless=self.headless)\n",
    "        context = browser.new_context()\n",
    "        page = context.new_page()\n",
    "        page.goto(url, wait_until=\"networkidle\")\n",
    "        return pw, browser, context, page\n",
    "\n",
    "    def search(self, query: str, page_number: int = 1):\n",
    "        \"\"\"\n",
    "        Perform a TechCrunch search using Playwright-rendered DOM scraping.\n",
    "\n",
    "        TechCrunch does pagination using:\n",
    "        https://techcrunch.com/page/<n>/?s=query\n",
    "        \"\"\"\n",
    "\n",
    "        if page_number == 1:\n",
    "            url = f\"{self.BASE_URL}{query}\"\n",
    "        else:\n",
    "            url = f\"https://techcrunch.com/page/{page_number}/?s={query}\"\n",
    "\n",
    "        pw, browser, context, page = self._load_page(url)\n",
    "\n",
    "        # Select rendered article cards\n",
    "        articles = page.locator(\"div.post-block\")\n",
    "\n",
    "        results = []\n",
    "        count = articles.count()\n",
    "\n",
    "        for i in range(count):\n",
    "            card = articles.nth(i)\n",
    "            title = card.locator(\"h2 a\").inner_text()\n",
    "            link = card.locator(\"h2 a\").get_attribute(\"href\")\n",
    "            snippet = card.locator(\"div.post-block__content\").inner_text()\n",
    "            date = card.locator(\"time\").get_attribute(\"datetime\")\n",
    "\n",
    "            results.append({\n",
    "                \"title\": title.strip(),\n",
    "                \"url\": link.strip(),\n",
    "                \"snippet\": snippet.strip(),\n",
    "                \"date\": date,\n",
    "            })\n",
    "\n",
    "        browser.close()\n",
    "        pw.stop()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def fetch_article(self, url: str) -> str:\n",
    "        \"\"\"Fetch full TC article and return Markdown.\"\"\"\n",
    "        pw, browser, context, page = self._load_page(url)\n",
    "        html = page.content()\n",
    "        browser.close()\n",
    "        pw.stop()\n",
    "\n",
    "        md = markdownify(html)\n",
    "        return clean_markdown(md)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Autogen Tool Wrapper\n",
    "# ----------------------------------------------------------------------\n",
    "class TechCrunchSearchTool:\n",
    "    \"\"\"\n",
    "    Autogen FunctionTool wrapper exposing:\n",
    "    - search_tc(query, page)\n",
    "    - open_tc_result(index)\n",
    "    - next_tc_page()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api: TechCrunchSearchAPI):\n",
    "        self.api = api\n",
    "        self.current_query = None\n",
    "        self.current_page = 1\n",
    "        self.current_results = []\n",
    "\n",
    "        self.search_tool = FunctionTool(self.search, name=\"search_tc\", description=self.search.__doc__)\n",
    "        self.open_tool = FunctionTool(self.open, name=\"open_tc_result\", description=self.open.__doc__)\n",
    "        self.next_page_tool = FunctionTool(self.next_page, name=\"next_tc_page\", description=self.next_page.__doc__)\n",
    "\n",
    "    def search(self, query: str, page: int = 1):\n",
    "        \"\"\"\n",
    "        Search TechCrunch on query.\n",
    "        \"\"\"\n",
    "        self.current_query = query\n",
    "        self.current_page = page\n",
    "        self.current_results = self.api.search(query, page)\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"page\": page,\n",
    "            \"results\": self.current_results,\n",
    "        }\n",
    "\n",
    "    def open(self, index: int):\n",
    "        \"\"\"\n",
    "        Open techcruch article based on selected result index\n",
    "        \"\"\"\n",
    "        if index < 0 or index >= len(self.current_results):\n",
    "            return {\"error\": \"Result index out of range.\"}\n",
    "\n",
    "        res = self.current_results[index]\n",
    "        md = self.api.fetch_article(res[\"url\"])\n",
    "\n",
    "        return {\n",
    "            \"title\": res[\"title\"],\n",
    "            \"url\": res[\"url\"],\n",
    "            \"content_markdown\": md,\n",
    "        }\n",
    "\n",
    "    def next_page(self):\n",
    "        \"\"\"\n",
    "        Go to next page of current query.\n",
    "        \"\"\"\n",
    "        if not self.current_query:\n",
    "            return {\"error\": \"No active query to paginate.\"}\n",
    "\n",
    "        self.current_page += 1\n",
    "        self.current_results = self.api.search(self.current_query, self.current_page)\n",
    "\n",
    "        return {\n",
    "            \"query\": self.current_query,\n",
    "            \"page\": self.current_page,\n",
    "            \"results\": self.current_results,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b0512caa-fba8-4b94-8903-99f445118a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TechCrunchSearchAPI(headless=True)\n",
    "techcrunch_tools = TechCrunchSearchTool(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "362e39ee-d9cd-461d-a1b8-9690f7e796af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'drones', 'page': 1, 'results': []}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await techcrunch_tools.search_tool.run_json({\"query\": \"drones\",\"page\":1}, CancellationToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622dd32-fca8-4fd0-8b8e-fdc2bffa0c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
